# Vector configuration for comprehensive log collection
# Includes: AG service, monitoring stack, and OS-level logs
# Replaces Promtail with equivalent functionality

# Data directory for disk buffers
data_dir = "/home/pde/.local/share/vector"

# ============================================================================
# Source: AG Service (systemd journal)
# ============================================================================
[sources.ag_journald]
type = "journald"
include_units = ["ag.service"]
current_boot_only = false

[transforms.ag_labels]
type = "remap"
inputs = ["ag_journald"]
source = '''
  # Basic labels
  .systemd_unit = .SYSTEMD_UNIT
  .hostname = .host
  .priority = string!(.PRIORITY)
  .syslog_identifier = .SYSLOG_IDENTIFIER
  .job = "systemd-journal"
  .host_label = "localhost"
  
  # Extract log level from message
  level_match = parse_regex(.message, r'\\s+(TRACE|DEBUG|INFO|WARN|ERROR|FATAL)\\s+') ?? {}
  if exists(level_match.1) {
    .level = level_match.1
  }
  
  # Extract request_id
  request_match = parse_regex(.message, r'request_id=([a-f0-9-]+)') ?? {}
  if exists(request_match.1) {
    .request_id = request_match.1
  }
  
  # Extract HTTP status
  status_match = parse_regex(.message, r'status=(\\d{3})') ?? {}
  if exists(status_match.1) {
    .http_status = status_match.1
  }
  
  # Extract HTTP method
  method_match = parse_regex(.message, r'method=(GET|POST|PUT|DELETE|PATCH|HEAD|OPTIONS)') ?? {}
  if exists(method_match.1) {
    .http_method = method_match.1
  }
  
  # Extract duration
  duration_match = parse_regex(.message, r'duration_ms=(\\d+)') ?? {}
  if exists(duration_match.1) {
    .duration_ms = duration_match.1
  }
  
  # Flag errors and warnings
  if .level == "ERROR" {
    .is_error = "true"
  }
  if .level == "WARN" {
    .is_warning = "true"
  }
'''

[sinks.loki_ag]
type = "loki"
inputs = ["ag_labels"]
endpoint = "http://127.0.0.1:3100"
encoding.codec = "json"
labels.job = "{{ job }}"
labels.systemd_unit = "{{ systemd_unit }}"
labels.hostname = "{{ hostname }}"
labels.priority = "{{ priority }}"
labels.host = "{{ host_label }}"
labels.level = "{{ level }}"
labels.request_id = "{{ request_id }}"
labels.http_status = "{{ http_status }}"
labels.http_method = "{{ http_method }}"
labels.duration_ms = "{{ duration_ms }}"
labels.is_error = "{{ is_error }}"
labels.is_warning = "{{ is_warning }}"
healthcheck.enabled = true
batch.max_bytes = 1048576
batch.timeout_secs = 1

# ============================================================================
# Source: Monitoring Stack Services (systemd journal)
# ============================================================================
[sources.monitoring_journald]
type = "journald"
include_units = ["loki.service", "otelcol.service", "prometheus.service", "grafana-server.service", "alertmanager.service"]
current_boot_only = false

[transforms.monitoring_labels]
type = "remap"
inputs = ["monitoring_journald"]
source = '''
  .systemd_unit = .SYSTEMD_UNIT
  .hostname = .host
  .priority = string!(.PRIORITY)
  .syslog_identifier = .SYSLOG_IDENTIFIER
  .job = "systemd-monitoring"
  .host_label = "localhost"
  
  # Extract log level
  level_match = parse_regex(.message, r'level=(debug|info|warn|error|fatal)') ?? {}
  if exists(level_match.1) {
    .level = level_match.1
    if .level == "error" {
      .is_error = "true"
    }
    if .level == "warn" {
      .is_warning = "true"
    }
  }
'''

[sinks.loki_monitoring]
type = "loki"
inputs = ["monitoring_labels"]
endpoint = "http://127.0.0.1:3100"
encoding.codec = "json"
labels.job = "{{ job }}"
labels.systemd_unit = "{{ systemd_unit }}"
labels.hostname = "{{ hostname }}"
labels.priority = "{{ priority }}"
labels.host = "{{ host_label }}"
labels.level = "{{ level }}"
labels.is_error = "{{ is_error }}"
labels.is_warning = "{{ is_warning }}"
healthcheck.enabled = true
batch.max_bytes = 1048576
batch.timeout_secs = 1

# ============================================================================
# Source: AG File Logs
# ============================================================================
[sources.ag_file_logs]
type = "file"
include = ["/home/pde/.agentic-rag/logs/backend.log.*"]
read_from = "beginning"

[transforms.ag_file_labels]
type = "remap"
inputs = ["ag_file_logs"]
source = '''
  .job = "ag-file-logs"
  .host_label = "localhost"
  
  # Extract log level from JSON or text
  level_match = parse_regex(.message, r'\\s+(TRACE|DEBUG|INFO|WARN|ERROR|FATAL)\\s+') ?? {}
  if exists(level_match.1) {
    .level = level_match.1
  }
  
  # Extract request_id
  request_match = parse_regex(.message, r'request_id=([a-f0-9-]+)') ?? {}
  if exists(request_match.1) {
    .request_id = request_match.1
  }
  
  # Extract HTTP status
  status_match = parse_regex(.message, r'status=(\\d{3})') ?? {}
  if exists(status_match.1) {
    .http_status = status_match.1
  }
  
  # Flag errors
  if .level == "ERROR" {
    .is_error = "true"
  }
  if .level == "WARN" {
    .is_warning = "true"
  }
'''

[sinks.loki_ag_files]
type = "loki"
inputs = ["ag_file_labels"]
endpoint = "http://127.0.0.1:3100"
encoding.codec = "json"
labels.job = "{{ job }}"
labels.host = "{{ host_label }}"
labels.level = "{{ level }}"
labels.request_id = "{{ request_id }}"
labels.http_status = "{{ http_status }}"
labels.is_error = "{{ is_error }}"
labels.is_warning = "{{ is_warning }}"
healthcheck.enabled = true
batch.max_bytes = 1048576
batch.timeout_secs = 1

# ============================================================================
# Source: System Errors (systemd journal - priority 0-3)
# ============================================================================
[sources.system_errors_journald]
type = "journald"
current_boot_only = false

[transforms.system_errors_filter]
type = "filter"
inputs = ["system_errors_journald"]
condition = 'to_int!(.PRIORITY) <= 3'

[transforms.system_errors_labels]
type = "remap"
inputs = ["system_errors_filter"]
source = '''
  .systemd_unit = .SYSTEMD_UNIT
  .hostname = .host
  .priority = string!(.PRIORITY)
  .syslog_identifier = .SYSLOG_IDENTIFIER
  .job = "system-errors"
  .host_label = "localhost"
  .is_error = "true"
'''

[sinks.loki_system_errors]
type = "loki"
inputs = ["system_errors_labels"]
endpoint = "http://127.0.0.1:3100"
encoding.codec = "json"
labels.job = "{{ job }}"
labels.systemd_unit = "{{ systemd_unit }}"
labels.hostname = "{{ hostname }}"
labels.priority = "{{ priority }}"
labels.host = "{{ host_label }}"
labels.is_error = "{{ is_error }}"
healthcheck.enabled = true
batch.max_bytes = 1048576
batch.timeout_secs = 1

# ============================================================================
# Source: Kernel Logs
# ============================================================================
[sources.kernel_logs]
type = "file"
include = ["/var/log/kern.log"]
read_from = "end"

[transforms.kernel_labels]
type = "remap"
inputs = ["kernel_logs"]
source = '''
  .job = "kernel"
  .host_label = "localhost"
  .log_type = "kernel"
  
  # Flag errors and warnings
  if match(.message, r'(?i)(error|fail|critical|panic|oops|bug|segfault)') {
    .is_error = "true"
  }
  if match(.message, r'(?i)(warn|warning)') {
    .is_warning = "true"
  }
'''

[sinks.loki_kernel]
type = "loki"
inputs = ["kernel_labels"]
endpoint = "http://127.0.0.1:3100"
encoding.codec = "json"
labels.job = "{{ job }}"
labels.host = "{{ host_label }}"
labels.log_type = "{{ log_type }}"
labels.is_error = "{{ is_error }}"
labels.is_warning = "{{ is_warning }}"
healthcheck.enabled = true
batch.max_bytes = 1048576
batch.timeout_secs = 1

# ============================================================================
# Source: Authentication Logs
# ============================================================================
[sources.auth_logs]
type = "file"
include = ["/var/log/auth.log"]
read_from = "end"

[transforms.auth_labels]
type = "remap"
inputs = ["auth_logs"]
source = '''
  .job = "auth"
  .host_label = "localhost"
  .log_type = "security"
  
  # Extract auth events
  if match(.message, r'Failed password') {
    .auth_event = "Failed password"
  } else if match(.message, r'Accepted password') {
    .auth_event = "Accepted password"
  } else if match(.message, r'authentication failure') {
    .auth_event = "authentication failure"
  } else if match(.message, r'session opened') {
    .auth_event = "session opened"
  } else if match(.message, r'session closed') {
    .auth_event = "session closed"
  } else if match(.message, r'sudo') {
    .auth_event = "sudo"
  }
  
  # Flag failures
  if match(.message, r'(?i)(failed|failure|invalid|error|denied)') {
    .is_error = "true"
  }
  if match(.message, r'(?i)(warn|warning)') {
    .is_warning = "true"
  }
'''

[sinks.loki_auth]
type = "loki"
inputs = ["auth_labels"]
endpoint = "http://127.0.0.1:3100"
encoding.codec = "json"
labels.job = "{{ job }}"
labels.host = "{{ host_label }}"
labels.log_type = "{{ log_type }}"
labels.auth_event = "{{ auth_event }}"
labels.is_error = "{{ is_error }}"
labels.is_warning = "{{ is_warning }}"
healthcheck.enabled = true
batch.max_bytes = 1048576
batch.timeout_secs = 1

# ============================================================================
# Source: System Logs (syslog)
# ============================================================================
[sources.syslog_file]
type = "file"
include = ["/var/log/syslog"]
read_from = "end"

[transforms.syslog_labels]
type = "remap"
inputs = ["syslog_file"]
source = '''
  .job = "syslog"
  .host_label = "localhost"
  .log_type = "system"
  
  # Extract process name
  process_match = parse_regex(.message, r'\\w{3}\\s+\\d{1,2}\\s+\\d{2}:\\d{2}:\\d{2}\\s+\\S+\\s+([^\\[\\s:]+)') ?? {}
  if exists(process_match.1) {
    .process = process_match.1
  }
  
  # Flag errors and warnings
  if match(.message, r'(?i)(error|err|fail|critical|panic|fatal)') {
    .is_error = "true"
  }
  if match(.message, r'(?i)(warn|warning)') {
    .is_warning = "true"
  }
'''

[sinks.loki_syslog]
type = "loki"
inputs = ["syslog_labels"]
endpoint = "http://127.0.0.1:3100"
encoding.codec = "json"
labels.job = "{{ job }}"
labels.host = "{{ host_label }}"
labels.log_type = "{{ log_type }}"
labels.process = "{{ process }}"
labels.is_error = "{{ is_error }}"
labels.is_warning = "{{ is_warning }}"
healthcheck.enabled = true
batch.max_bytes = 1048576
batch.timeout_secs = 1

# ============================================================================
# Internal Metrics (monitor Vector itself)
# ============================================================================
[sources.internal_metrics]
type = "internal_metrics"

[sinks.prometheus_exporter]
type = "prometheus_exporter"
inputs = ["internal_metrics"]
address = "0.0.0.0:9598"
default_namespace = "vector"
