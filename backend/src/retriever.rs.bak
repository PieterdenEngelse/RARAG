use tantivy::{
    Index, 
    collector::TopDocs, 
    query::QueryParser,
    schema::{Schema, TEXT, STORED, Field, Value},
    directory::MmapDirectory,
    TantivyError,
    query::QueryParserError,
    directory::error::OpenDirectoryError,
    IndexWriter,
};
use serde::{Serialize, Deserialize};
use std::fmt;
use std::collections::HashMap;
use std::fs::File;
use std::io::{Write, Read};
use std::sync::Arc;
use std::sync::atomic::{AtomicUsize, Ordering};

/// Custom error type for Retriever operations
#[derive(Debug, Serialize, Deserialize)]
pub enum RetrieverError {
    TantivyError(String),
    IoError(String),
    IndexError(String),
    VectorError(String),
    QueryParserError(String),
    DirectoryError(String),
    SerializationError(String),
}

impl fmt::Display for RetrieverError {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        match self {
            RetrieverError::TantivyError(e) => write!(f, "Tantivy error: {}", e),
            RetrieverError::IoError(e) => write!(f, "IO error: {}", e),
            RetrieverError::IndexError(msg) => write!(f, "Index error: {}", msg),
            RetrieverError::VectorError(msg) => write!(f, "Vector error: {}", msg),
            RetrieverError::QueryParserError(msg) => write!(f, "Query parser error: {}", msg),
            RetrieverError::DirectoryError(msg) => write!(f, "Directory error: {}", msg),
            RetrieverError::SerializationError(msg) => write!(f, "Serialization error: {}", msg),
        }
    }
}

impl std::error::Error for RetrieverError {}

impl From<TantivyError> for RetrieverError {
    fn from(err: TantivyError) -> Self {
        RetrieverError::TantivyError(err.to_string())
    }
}

impl From<std::io::Error> for RetrieverError {
    fn from(err: std::io::Error) -> Self {
        RetrieverError::IoError(err.to_string())
    }
}

impl From<QueryParserError> for RetrieverError {
    fn from(err: QueryParserError) -> Self {
        RetrieverError::QueryParserError(err.to_string())
    }
}

impl From<OpenDirectoryError> for RetrieverError {
    fn from(err: OpenDirectoryError) -> Self {
        RetrieverError::DirectoryError(err.to_string())
    }
}

#[derive(Serialize, Deserialize)]
struct VectorStorage {
    vectors: Vec<Vec<f32>>,
    doc_id_to_vector_idx: HashMap<String, usize>,
}

/// Retriever stores vectors and handles search operations.
pub struct Retriever {
    pub vectors: Vec<Vec<f32>>,
    pub index: Index,
    pub title_field: Field,
    pub content_field: Field,
    pub doc_id_to_vector_idx: HashMap<String, usize>,
    pub vector_file_path: String,
    pub auto_save_threshold: usize,
    documents_since_save: Arc<AtomicUsize>,
    index_writer: Option<IndexWriter>,
    batch_mode: bool,
}

// Helper function for cosine similarity
fn cosine_similarity(a: &[f32], b: &[f32]) -> f32 {
    let dot_product: f32 = a.iter().zip(b.iter()).map(|(x, y)| x * y).sum();
    let magnitude_a: f32 = a.iter().map(|x| x * x).sum::<f32>().sqrt();
    let magnitude_b: f32 = b.iter().map(|x| x * x).sum::<f32>().sqrt();
    
    if magnitude_a == 0.0 || magnitude_b == 0.0 {
        0.0
    } else {
        dot_product / (magnitude_a * magnitude_b)
    }
}

impl Retriever {
    pub fn new(index_dir: &str) -> Result<Self, RetrieverError> {
        let mut schema_builder = Schema::builder();
        let title_field = schema_builder.add_text_field("title", TEXT | STORED);
        let content_field = schema_builder.add_text_field("content", TEXT | STORED);
        let schema = schema_builder.build();
        let dir = MmapDirectory::open(index_dir)?;
        let index = Index::open_or_create(dir, schema)?;
        
        let mut retriever = Retriever {
            vectors: Vec::new(),
            index,
            title_field,
            content_field,
            doc_id_to_vector_idx: HashMap::new(),
            vector_file_path: "./vectors.json".to_string(),
            auto_save_threshold: 100,
            documents_since_save: Arc::new(AtomicUsize::new(0)),
            index_writer: None,
            batch_mode: false,
        };
        
        // Try to load existing vectors on startup
        if let Err(e) = retriever.load_vectors(&retriever.vector_file_path.clone()) {
            println!("No existing vectors found, starting fresh: {}", e);
        } else {
            println!("Loaded existing vectors from {}", retriever.vector_file_path);
        }
        
        Ok(retriever)
    }

    pub fn new_dummy() -> Result<Self, RetrieverError> {
        Self::new("./tantivy_index")
    }

    /// Start batch indexing mode - creates a single writer for multiple documents
    pub fn begin_batch(&mut self) -> Result<(), RetrieverError> {
        if self.index_writer.is_some() {
            return Err(RetrieverError::IndexError("Batch already in progress".to_string()));
        }
        
        self.index_writer = Some(self.index.writer(50_000_000)?);
        self.batch_mode = true;
        println!("Batch indexing mode started");
        Ok(())
    }

    /// End batch indexing mode - commits all pending documents
    pub fn end_batch(&mut self) -> Result<(), RetrieverError> {
        if let Some(mut writer) = self.index_writer.take() {
            writer.commit()?;
            self.batch_mode = false;
            println!("Batch indexing mode ended, changes committed");
            Ok(())
        } else {
            Err(RetrieverError::IndexError("No batch in progress".to_string()))
        }
    }

    /// Add multiple documents in batch mode
    pub fn add_documents_batch(&mut self, documents: Vec<(String, String)>) -> Result<usize, RetrieverError> {
        let was_batch = self.batch_mode;
        
        if !was_batch {
            self.begin_batch()?;
        }
        
        let mut count = 0;
        for (title, content) in documents {
            if let Err(e) = self.add_document_to_batch(&title, &content) {
                eprintln!("Failed to add document '{}': {}", title, e);
            } else {
                count += 1;
            }
        }
        
        if !was_batch {
            self.end_batch()?;
        }
        
        Ok(count)
    }

    /// Add a document to the current batch (internal use)
    fn add_document_to_batch(&mut self, title: &str, content: &str) -> Result<(), RetrieverError> {
        if !self.batch_mode {
            return Err(RetrieverError::IndexError("Not in batch mode".to_string()));
        }
        
        let mut doc = tantivy::TantivyDocument::default();
        doc.add_text(self.title_field, title);
        doc.add_text(self.content_field, content);
        
        if let Some(writer) = &mut self.index_writer {
            writer.add_document(doc)?;
            Ok(())
        } else {
            Err(RetrieverError::IndexError("No writer available".to_string()))
        }
    }

    pub fn search(&self, query_str: &str) -> Result<Vec<String>, RetrieverError> {
        let reader = self.index.reader()?;
        let searcher = reader.searcher();
        let parser = QueryParser::for_index(&self.index, vec![self.title_field, self.content_field]);
        let query = parser.parse_query(query_str)?;
        let top_docs = searcher.search(&query, &TopDocs::with_limit(10))?;
        
        let mut results = Vec::new();
        for (_score, doc_address) in top_docs {
            let doc = searcher.doc::<tantivy::TantivyDocument>(doc_address)?;
            let content = doc
                .get_first(self.content_field)
                .and_then(|v| v.as_str())
                .unwrap_or("")
                .to_string();
            results.push(content);
        }
        Ok(results)
    }

    pub fn add_vector(&mut self, vector: Vec<f32>) {
        self.vectors.push(vector);
        self.check_auto_save();
    }

    pub fn add_vector_with_id(&mut self, doc_id: String, vector: Vec<f32>) {
        let idx = self.vectors.len();
        self.vectors.push(vector);
        self.doc_id_to_vector_idx.insert(doc_id, idx);
        self.check_auto_save();
    }

    fn check_auto_save(&mut self) {
        let count = self.documents_since_save.fetch_add(1, Ordering::SeqCst) + 1;
        
        if count >= self.auto_save_threshold {
            if let Err(e) = self.save_vectors(&self.vector_file_path.clone()) {
                eprintln!("Auto-save failed: {}", e);
            } else {
                println!("Auto-saved vectors after {} documents", count);
                self.documents_since_save.store(0, Ordering::SeqCst);
            }
        }
    }

    pub fn vector_search(&self, query_vector: &[f32], top_k: usize) -> Vec<(usize, f32)> {
        let mut similarities: Vec<(usize, f32)> = self.vectors
            .iter()
            .enumerate()
            .map(|(idx, vec)| (idx, cosine_similarity(query_vector, vec)))
            .collect();
        
        // Sort by similarity (descending)
        similarities.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap());
        
        // Return top K results
        similarities.into_iter().take(top_k).collect()
    }

    pub fn hybrid_search(&self, query: &str, query_vector: Option<&[f32]>) -> Result<Vec<String>, RetrieverError> {
        // Get keyword search results
        let keyword_results = self.search(query)?;
        
        // If no query vector provided, return keyword results only
        let query_vec = match query_vector {
            Some(v) => v,
            None => return Ok(keyword_results),
        };
        
        // Get vector search results
        let vector_results = self.vector_search(query_vec, 10);
        
        // Merge results using Reciprocal Rank Fusion (RRF)
        let k = 60.0; // RRF constant
        let mut score_map: HashMap<String, f32> = HashMap::new();
        
        // Score keyword results
        for (rank, content) in keyword_results.iter().enumerate() {
            let score = 1.0 / (k + (rank as f32) + 1.0);
            *score_map.entry(content.clone()).or_insert(0.0) += score;
        }
        
        // Score vector results (map indices back to content)
        for (rank, (idx, _similarity)) in vector_results.iter().enumerate() {
            // Try to find the document content for this vector index
            if let Some(content) = self.get_content_by_vector_idx(*idx) {
                let score = 1.0 / (k + (rank as f32) + 1.0);
                *score_map.entry(content).or_insert(0.0) += score;
            }
        }
        
        // Sort by combined score
        let mut merged_results: Vec<(String, f32)> = score_map.into_iter().collect();
        merged_results.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap());
        
        // Return top 10 results
        Ok(merged_results.into_iter().take(10).map(|(content, _)| content).collect())
    }

    fn get_content_by_vector_idx(&self, idx: usize) -> Option<String> {
        // Find document ID for this vector index
        for (doc_id, &vec_idx) in &self.doc_id_to_vector_idx {
            if vec_idx == idx {
                return Some(doc_id.clone());
            }
        }
        None
    }

    // Original API-compatible version (for backward compatibility)
    pub fn rerank_by_similarity(&self, _query: &str, candidates: &Vec<String>) -> Vec<String> {
        let mut results = candidates.clone();
        results.reverse(); // simple placeholder
        results
    }

    // New vector-based reranking
    pub fn rerank_by_vector_similarity(&self, query_vector: &[f32], candidate_indices: &[usize]) -> Result<Vec<(usize, f32)>, RetrieverError> {
        let mut scored_candidates: Vec<(usize, f32)> = candidate_indices
            .iter()
            .filter_map(|&idx| {
                if idx < self.vectors.len() {
                    Some((idx, cosine_similarity(query_vector, &self.vectors[idx])))
                } else {
                    None
                }
            })
            .collect();
        
        if scored_candidates.is_empty() && !candidate_indices.is_empty() {
            return Err(RetrieverError::VectorError("No valid candidate indices found".to_string()));
        }
        
        // Sort by similarity score (descending)
        scored_candidates.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap());
        
        Ok(scored_candidates)
    }

    pub fn summarize_chunks(&self, _query: &str, candidates: &Vec<String>) -> String {
        format!("Summary for {} chunks", candidates.len())
    }

    pub fn index_document(&mut self, doc: impl tantivy::Document) -> Result<(), RetrieverError> {
        let mut index_writer = self.index.writer(50_000_000)?;
        index_writer.add_document(doc)?;
        index_writer.commit()?;
        Ok(())
    }

    pub fn add_document(&mut self, title: &str, content: &str) -> Result<(), RetrieverError> {
        // If in batch mode, use batch method
        if self.batch_mode {
            return self.add_document_to_batch(title, content);
        }
        
        // Otherwise, create single-use writer
        let mut doc = tantivy::TantivyDocument::default();
        doc.add_text(self.title_field, title);
        doc.add_text(self.content_field, content);
        
        let mut index_writer = self.index.writer(50_000_000)?;
        index_writer.add_document(doc)?;
        index_writer.commit()?;
        Ok(())
    }

    pub fn commit(&mut self) -> Result<(), RetrieverError> {
        // If in batch mode, end it
        if self.batch_mode {
            self.end_batch()?;
        }
        
        // Force save vectors
        self.save_vectors(&self.vector_file_path.clone())?;
        Ok(())
    }

    pub fn save_vectors(&self, filename: &str) -> Result<(), RetrieverError> {
        let storage = VectorStorage {
            vectors: self.vectors.clone(),
            doc_id_to_vector_idx: self.doc_id_to_vector_idx.clone(),
        };
        
        let json = serde_json::to_string(&storage)
            .map_err(|e| RetrieverError::SerializationError(e.to_string()))?;
        
        let mut file = File::create(filename)?;
        file.write_all(json.as_bytes())?;
        
        Ok(())
    }

    pub fn load_vectors(&mut self, filename: &str) -> Result<(), RetrieverError> {
        let mut file = File::open(filename)?;
        let mut contents = String::new();
        file.read_to_string(&mut contents)?;
        
        let storage: VectorStorage = serde_json::from_str(&contents)
            .map_err(|e| RetrieverError::SerializationError(e.to_string()))?;
        
        self.vectors = storage.vectors;
        self.doc_id_to_vector_idx = storage.doc_id_to_vector_idx;
        
        Ok(())
    }

    pub fn force_save(&self) -> Result<(), RetrieverError> {
        println!("Manual save triggered");
        self.save_vectors(&self.vector_file_path)
    }

    pub fn set_auto_save_threshold(&mut self, threshold: usize) {
        self.auto_save_threshold = threshold;
        println!("Auto-save threshold set to {} documents", threshold);
    }

    pub fn index_chunk(&mut self, chunk_id: &str, chunk_text: &str, vector: &Vec<f32>) -> Result<(), RetrieverError> {
        // Add the document to Tantivy index
        self.add_document(chunk_id, chunk_text)?;
        
        // Add vector with document ID mapping
        self.add_vector_with_id(chunk_text.to_string(), vector.clone());
        
        Ok(())
    }
}

// Implement Drop to save on shutdown
impl Drop for Retriever {
    fn drop(&mut self) {
        // End batch mode if active
        if self.batch_mode {
            if let Err(e) = self.end_batch() {
                eprintln!("Failed to end batch on shutdown: {}", e);
            }
        }
        
        println!("Retriever shutting down, saving vectors...");
        if let Err(e) = self.save_vectors(&self.vector_file_path.clone()) {
            eprintln!("Failed to save vectors on shutdown: {}", e);
        } else {
            println!("Vectors saved successfully on shutdown");
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::fs;
    use std::sync::atomic::{AtomicUsize, Ordering};

    static TEST_COUNTER: AtomicUsize = AtomicUsize::new(0);

    fn setup_test_retriever() -> (Retriever, String) {
        let test_id = TEST_COUNTER.fetch_add(1, Ordering::SeqCst);
        let test_dir = format!("./test_tantivy_index_{}", test_id);
        let test_vector_file = format!("./test_vectors_{}.json", test_id);
        
        let _ = fs::remove_dir_all(&test_dir);
        fs::create_dir_all(&test_dir).unwrap();
        
        let mut retriever = Retriever::new(&test_dir).unwrap();
        retriever.vector_file_path = test_vector_file;
        retriever.auto_save_threshold = 1000; // Disable auto-save for tests
        (retriever, test_dir)
    }

    fn cleanup_test_files(test_dir: &str, vector_file: &str) {
        let _ = fs::remove_file(vector_file);
        let _ = fs::remove_dir_all(test_dir);
    }

    #[test]
    fn test_cosine_similarity() {
        let v1 = vec![1.0, 0.0, 0.0];
        let v2 = vec![1.0, 0.0, 0.0];
        let v3 = vec![0.0, 1.0, 0.0];
        
        assert!((cosine_similarity(&v1, &v2) - 1.0).abs() < 0.001);
        assert!((cosine_similarity(&v1, &v3)).abs() < 0.001);
    }

    #[test]
    fn test_add_and_search_document() {
        let (mut retriever, test_dir) = setup_test_retriever();
        let vector_file = retriever.vector_file_path.clone();
        
        retriever.add_document("Test Title", "This is test content about Rust").unwrap();
        
        let results = retriever.search("Rust").unwrap();
        assert!(!results.is_empty());
        assert_eq!(results[0], "This is test content about Rust");
        
        drop(retriever);
        cleanup_test_files(&test_dir, &vector_file);
    }

    #[test]
    fn test_batch_indexing() {
        let (mut retriever, test_dir) = setup_test_retriever();
        let vector_file = retriever.vector_file_path.clone();
        
        let docs = vec![
            ("Doc1".to_string(), "First document".to_string()),
            ("Doc2".to_string(), "Second document".to_string()),
            ("Doc3".to_string(), "Third document".to_string()),
        ];
        
        let count = retriever.add_documents_batch(docs).unwrap();
        assert_eq!(count, 3);
        
        let results = retriever.search("document").unwrap();
        assert_eq!(results.len(), 3);
        
        drop(retriever);
        cleanup_test_files(&test_dir, &vector_file);
    }

    #[test]
    fn test_vector_operations() {
        let (mut retriever, test_dir) = setup_test_retriever();
        let vector_file = retriever.vector_file_path.clone();
        
        retriever.add_vector(vec![1.0, 0.0, 0.0]);
        retriever.add_vector(vec![0.9, 0.1, 0.0]);
        retriever.add_vector(vec![0.0, 1.0, 0.0]);
        
        let query = vec![1.0, 0.0, 0.0];
        let results = retriever.vector_search(&query, 2);
        
        assert_eq!(results.len(), 2);
        assert_eq!(results[0].0, 0); // First vector is most similar
        assert!(results[0].1 > results[1].1); // Check ordering
        
        drop(retriever);
        cleanup_test_files(&test_dir, &vector_file);
    }

    #[test]
    fn test_save_and_load_vectors() {
        let (mut retriever, test_dir) = setup_test_retriever();
        let vector_file = retriever.vector_file_path.clone();
        
        retriever.add_vector_with_id("doc1".to_string(), vec![1.0, 2.0, 3.0]);
        retriever.add_vector_with_id("doc2".to_string(), vec![4.0, 5.0, 6.0]);
        
        retriever.save_vectors(&vector_file).unwrap();
        
        // Create a new retriever with a different test ID
        let test_id = TEST_COUNTER.fetch_add(1, Ordering::SeqCst);
        let test_dir2 = format!("./test_tantivy_index_{}", test_id);
        let _ = fs::create_dir_all(&test_dir2);
        
        let mut retriever2 = Retriever::new(&test_dir2).unwrap();
        retriever2.vector_file_path = vector_file.clone();
        retriever2.load_vectors(&vector_file).unwrap();
        
        assert_eq!(retriever2.vectors.len(), 2);
        assert_eq!(retriever2.doc_id_to_vector_idx.len(), 2);
        
        drop(retriever);
        drop(retriever2);
        cleanup_test_files(&test_dir, &vector_file);
        cleanup_test_files(&test_dir2, &vector_file);
    }

    #[test]
    fn test_rerank_by_vector_similarity() {
        let (mut retriever, test_dir) = setup_test_retriever();
        let vector_file = retriever.vector_file_path.clone();
        
        retriever.add_vector(vec![1.0, 0.0, 0.0]);
        retriever.add_vector(vec![0.0, 1.0, 0.0]);
        retriever.add_vector(vec![0.9, 0.1, 0.0]);
        
        let query = vec![1.0, 0.0, 0.0];
        let candidates = vec![0, 1, 2];
        
        let results = retriever.rerank_by_vector_similarity(&query, &candidates).unwrap();
        
        assert_eq!(results.len(), 3);
        assert_eq!(results[0].0, 0); // Most similar
        assert_eq!(results[1].0, 2); // Second most similar
        assert_eq!(results[2].0, 1); // Least similar
        
        drop(retriever);
        cleanup_test_files(&test_dir, &vector_file);
    }

    #[test]
    fn test_batch_mode_errors() {
        let (mut retriever, test_dir) = setup_test_retriever();
        let vector_file = retriever.vector_file_path.clone();
        
        // Should fail - not in batch mode
        let result = retriever.add_document_to_batch("title", "content");
        assert!(result.is_err());
        
        // Start batch
        retriever.begin_batch().unwrap();
        
        // Should fail - already in batch mode
        let result = retriever.begin_batch();
        assert!(result.is_err());
        
        // Should succeed - in batch mode
        retriever.add_document_to_batch("title", "content").unwrap();
        
        // End batch
        retriever.end_batch().unwrap();
        
        // Should fail - no batch in progress
        let result = retriever.end_batch();
        assert!(result.is_err());
        
        drop(retriever);
        cleanup_test_files(&test_dir, &vector_file);
    }

    #[test]
    fn test_hybrid_search_without_vectors() {
        let (mut retriever, test_dir) = setup_test_retriever();
        let vector_file = retriever.vector_file_path.clone();
        
        retriever.add_document("Test", "Rust programming").unwrap();
        
        let results = retriever.hybrid_search("Rust", None).unwrap();
        assert!(!results.is_empty());
        
        drop(retriever);
        cleanup_test_files(&test_dir, &vector_file);
    }

    #[test]
    fn test_index_chunk() {
        let (mut retriever, test_dir) = setup_test_retriever();
        let vector_file = retriever.vector_file_path.clone();
        
        let vector = vec![1.0, 2.0, 3.0];
        retriever.index_chunk("chunk1", "This is a chunk", &vector).unwrap();
        
        assert_eq!(retriever.vectors.len(), 1);
        
        let results = retriever.search("chunk").unwrap();
        assert!(!results.is_empty());
        
        drop(retriever);
        cleanup_test_files(&test_dir, &vector_file);
    }
}